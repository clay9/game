#+OPTIONS: ^:nil
#+OPTIONS: \n:t

* qybase9/net
  qybase9/net 是qyserver/kernel的最底层依赖,
  其base-line是handy网络库
** 目录说明
   | 目录               | 意义       | 备注                         |
   |--------------------+------------+------------------------------|
   | net                | 网络库核心 |                              |
   |--------------------+------------+------------------------------|
   | net_tools          | 网络库工具 |                              |
   |--------------------+------------+------------------------------|
   | tools              | 其他工具   | 部分是供上层(svr-kernel)使用 |
   |                    |            | 而非自己使用                 |
   |--------------------+------------+------------------------------|
   | define             | 定义文件   |                              |
   |--------------------+------------+------------------------------|
   | test_performance   | 性能测试   | 这里测试了千万并发           |
   |--------------------+------------+------------------------------|
   | test_unit          | 单元测试   |                              |
   |--------------------+------------+------------------------------|
   | Makefile           |            |                              |
   |--------------------+------------+------------------------------|
   | generate_depend.sh |            |                              |
   |--------------------+------------+------------------------------|
   | version.sh         |            |                              |
   |--------------------+------------+------------------------------|

** 文件解读
    | dir       | file           | desc                       | 备注                                     |
    |-----------+----------------+----------------------------+------------------------------------------|
    | net       | event_base     | 事件派发器                 | 单线程 && 多线程事件派发器               |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | event_imp      | event_base具体实现         |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | channel        | 事件                       | 封装了fd, 被epoll管理                    |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | tcpsvr         | tcp socket::server         |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | tcpconn        | tcp socket::client         |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | http           | http 协议                  | http实际是封装了一层tcp                  |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | stat-svr       | stat 协议(自定义)          | stat实际是封装了一层http                 |
    |-----------+----------------+----------------------------+------------------------------------------|
    |-----------+----------------+----------------------------+------------------------------------------|
    | net_tools | codec          | 消息解析(多种格式的data)   | LineCodec, LengthCodec, TcpHeadCodec等   |
    |           |                |                            | 需要什么类型的数据格式, 在这里自定义     |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | poller         | epoll的封装                | 用epoll来管理所有事件                    |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | port_posix     | 字节序转换                 | 大小字节                                 |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | net            | socket辅助                 | socket属性设置, ip地址转换, 缓冲区buffer |
    |-----------+----------------+----------------------------+------------------------------------------|
    |-----------+----------------+----------------------------+------------------------------------------|
    | tools     | conf           | 配置文件解析               |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | convert        | hex-string与普通string转换 |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | daemon         | 守护进程                   |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | dll            | dll调用                    |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | file           | 文件&&目录的操作           |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | logging        | 日志系统                   |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | qyfuncost      | 函数运行时间统计           |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | qysignal       | 信号设置                   |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | qytime         | 时间相关函数               |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | shell          | C++ 调用shell              |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | slice          | 字符串切片                 |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | status         |                            |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | threads        | 线程池                     |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | util           | 工具函数                   | 时间获取                                 |
    |           |                |                            | int, char*转换                           |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | uuid           | 创建uuid                   |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |-----------+----------------+----------------------------+------------------------------------------|
    | define    | heads.h        | 自身使用的头文件           |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | heads_qybase.h | 对外提供的头文件           |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|
    |           | net_struct.h   |                            |                                          |
    |-----------+----------------+----------------------------+------------------------------------------|

    : 与原handy相比, 去掉了udp协议

** 设计说明
   一个(或多个)线程 处理事件分发器
   有事件的话, 事件分发器通知 一个线程池(或自身线程)处理具体事件

   一个事件可能是tcp|upd|http 读|写|连接|关闭, 也可能是定时器, 也可能是io操作
   这源于linux 一切皆文件的原因
   而epoll可以管理事件, 而事件分发器实际也是封装了epoll处理

   一般事件分发器可以用单线程处理, 也可以使用多线程处理
   遵循per thread per epoll (或loop, 或base. 三者指代同一个东西)

   : 单线程事件派发器 EventBase
   : 多线程事件派发器 MultiBase
   : 事件 Channel

*** 设计理念
    1. 一切皆文件(fd), channel=fd+读写属性, poller管理channel(实际管理的是fd)
    2. server 与 conn关系
       server本身是维护了一系列conn
       管理手段是在创建conn时, 通过各种回调函数来控制conn的行为

       client只是一个conn而已
    3. 每个tcpserver或者tcpconn都有一个fd, 每个fd关注的属性(读或者写)会注册到一个channel
       : 要先看fd是什么, 再看fd关注的属性, 再看channel
    4. poller管理channel, channel中封装了fd, 而fd对应的可能是tcpconn或tcpserver
       所以channel是中间件, 最关键的还是看fd

*** 多线程的处理
    当其他线程需要操作conn连接的时候, 应当通过safeCall把操作交给conn的io线程来做
    safeCall是调用了io线程去处理数据
    #+BEGIN_EXAMPLE c++
      int main(int argc, const char* argv[]) {
          EventBase base;
          Signal::signal(SIGINT, [&]{ base.exit(); });
          TcpServerPtr svr = TcpServer::startServer(&base, "", 99);
          exitif(svr == NULL, "start tcp server failed");

          TcpConnPtr con = TcpConn::createConnection(&base, "localhost", 99);
          std::thread th([con,&base](){
              sleep(1);
              info("thread want to close an connection");
              base.safeCall([con](){ con->close(); }); //其他线程需要操作连接，应当通过safeCall把操作交给io线程来做
          });
          base.runAfter(1500, [&base](){base.exit();});
          base.loop();
          th.join();
      }
    #+END_EXAMPLE

*** 打印设计
    1. poller打印(INFO) fd的一生; 其他打印只有在发生错误的时候打印(WARNING,ERROR,FATAL)
       : fd一生 add, notify(read, write), modify, delete
    2. poller调用channel的info()函数详细描述fd信息
       - 创建channel的时候, 增加fd_type,表示fd对象的属性
       : fd_type 0->pipe fd; 1->tcpserver; 2->tcpconn; 3->httpSvr; ...
       - channel中的info()函数, 返回信息string信息
       #+BEGIN_EXAMPLE c++ fd信息
       //fd, fd_type, readable, writeable,
       "5 tcpserver, readable y, writeable n"
       #+END_EXAMPLE
       - poller调用info()打印
       #+BEGIN_EXAMPLE c++ poller打印
       LOG(INFO) << "add " << ch->info()
       //输出信息
       //"add 5 tcpserver, readable y, writeable n"
       #+END_EXAMPLE

*** TcpConn
**** socket相关
     调用socket的 writeImp 和 readImp来读写socket数据

     readImp --
     : onMsg()流程; onRead()的时候没有cb函数
     1. readImp把socket缓冲区中的数据 读取到自己的缓冲区input_
     2. 读取完毕之后, 调用自定义的readcb_回调函数
     : 现在的readcb_是在TcpConn::onMsg()中设置, 通过调用TcpConn::onRead()设置
     : 也可以自己调用TcpConn::onRead()来设置readcb_, 但是onRead()和onMSg()只有一个生效
     3. 调用readcb_函数
     : onMsg()中的readcb_中会先去解析数据codec_->tryDecode(CodeBase*), 然后调用cb回调函数
     : cb回调函数是上层程序调用onMsg()时候传递的
     4. 调用cb回调函数


     writeImp
     1. 如果channel可write, 则数据给output_
     2. 如果现在channel不可write, 则调用writeImp发送消息buff
     3. 如果消息buff没有发送完, 剩余的buff会给output_, 然后开启channel的write标志

**** 主要函数
     getInput()   获取输入缓冲区
     getOutput()  获取输出缓冲区


     TcpConn 回调接口
     - onRead      数据到达时回调
     - onWritable  缓冲区可写时回调
     - onState     tcp状态改变时回调
     - addIdleCB   tcp空闲时回调
     - onMsg       消息回调, 与onRead冲突

     TcpServer回调接口
     - onConnCreate 有client连接时, 创建一个TcpConn
     - onConnState  tcp状态改变回调
     - onConnRead   数据到达时回调
     - onConnMsg    消息回调, 与onConnRead冲突
**** onMsg()函数解析
     TcpConn读取socket缓冲区完成之后 通知上层的办法:
     readImp读取完成之后, 会调用回调函数readcb_

     readcb_可以通过onRead()来设置回调

     所以:
     1. 可以自己调用TcpConn::onRead()来设置其回调
     2. 可以调用onMsg()来设置cb_回调
     - onMsg()中通过调用onRead()定义了readcb_
     - onMsg()中定义的回调函数readcb_又调用了回调cb_
       而cb_可以通过调用onMsg()来设置
       这样就可以形成 readimp->readcb_->cb_

*** HttpConn
    HttpConn实际是封装了TcpConn

    HttpConnPtr回调接口
    - onHttpMsg

    HttpServer回调接口
    - onGet      -- 设置method "GET" 中的uri的回调
    - onRequest  -- 有client消息到达时调用
    - onDefault  -- 当找不到onRequest的时候调用
*** State
    状态服务器, 封装了HttpConn

*** 记录
    1. EventsImp中使用pipe()创建了管道
    2. PollerEpoll中封装了一个fd, poller自身的fd
    3. TcpConn的可写标志情形
       - 自己的缓冲区_output中有数据的时候. 设置为可写

*** socket数据格式
    这里是qygame/kernel中使用的socket数据格式.
    qybase/net本身不对数据格式做出限制. 需要什么格式, 在codec中定义即可
    #+BEGIN_EXAMPLE
      +-------+	-------------------------------+ ---------------+
      | short |	---> check code	   校验字段    |  TCP_Info      |   TCP_Head
      | uint  |	---> data  size	   数据大小    |                |
      +-------+	-------------------------------+                |
      +-------+	-------------------------------+                |
      | short |	---> main cmd      主命令      | TCP_Command    |
      | short |	---> sub  cmd      子命令      |                |
      | int64 |	---> user          玩家标识    |                |
      | int64 |	---> msgid         消息标识    |                |
      +-------+	-------------------------------+ ---------------+
      +-------+	------------------------------------------------>  具体数据, 大小为data size
      |       |
      |       |
      |       |
      +-------+
    #+END_EXAMPLE

** 千万并发测试
*** 分析 硬性条件
    需要达到千万连接
    1. 首先, fd要满足
       - 操作系统 总fd需要达到千万
       - 其次用户单进程fd的数量也要放大
         : 假设用户fd数量设置为1m, 那么就至少需要10个进程才能满足10m

    2. fd满足之后, ip+端口也需要满足
       一个tcp下的fd 可以认为是 source_ip:source_port + target_ip:tartget_port
       如果是cli与svr都是在单个机器上, 那么就需要配置port满足 source_port*target_port = 10m
       假设给svr200个port, 那么cli需要的port数量为:
       10 000 000 / 200 =50 000 = 50K
       系统端口为unsigned short 最大值为65535, 其中0-1024为系统使用, 所以剩余的port为64K, 满足要求

    3. fd与port都满足之后, 考虑内存mem, cpu, 带宽等硬件信息
       : 一条tcp消耗内存约为3K, 10m连接内存需求为30G
       : 通过设置tcp的read和write缓冲区来满足内存的使用情况

    4. 环境配置好了之后, 再设计代码
       - svr开启了10个进程, 共同监听cli的连接, 是因为svr内部已经做好了处理
         : nginx用的是锁. 而tcpsvr使用了更高级的内核XX...TODO 待学习

       - cli因为千万连接同时进行, 会导致大部分连接fd创建失败, 所以进行了分时连接,每100ms 2000个


    重点说明!!!
    这里千万测试 其实只是通道fd的创建,没有携带业务. 根据业务复杂程度, 会对fd的上限有影响.
    类比我与100个产品经理产生了业务关联, 但不代表我可以同时满足100个产品经理的需求..可能只能满足1个...
    所以最大连接数是与具体的业务关联的

*** 分析 并发条件
    直接影响
    1. 物理机     -- cpu
    2. 物理机     -- 内存
    3. 物理机     -- 带宽

*** svr 设计
    1. 开启了10个子进程
    2. 主进程开启一个tcpsvr, 用来获取子进程tcpsvrs的情形
    3. 每个子进程开启200个tcpsvr, 监听端口[100, 300)
    4. 每个子进程开启一个tcpconn, 向主进程的tcpsvr传递自身tcpsvrs的情形
       : 子进程延迟了100*1000 微妙 = 100毫秒, 方便主进程开启tcpsvr

*** cli 设计
    cli 需要完成50K * 200 = 10m
    1. 如果开启10个进程, 那么每个进程需要处理10m/10 = 1m

    2. 再来分析cli创建tcpconn的时间
       我们以100ms为粒度进行创建, 假设每100ms创建2000个, 那么总时间就是
       1m/2k = 1 000 000 / 2 000 = 500
       也就是说需要500个100ms 即50s可以全部创建完成


    cli 实际设计
    1. 开启了10个子进程
    2. 主进程开启一个tcpsvr, 用来获取子进程tcpsvrs的情形
    3. 每个子进程开启一个tcpconn, 向主进程的tcpsvr传递自身tcpsvrs的形情
    4. 每个子进程根据创建总数和创建时间, 获得x时间创建x个连接, 并去连接svr

*** 分析 socket_fd
    : ss -s 查看socket fd统计信息

    1. svr 内耗的socket_fd数量
       master    1tcpsvr
       : report tcpsvr
       sub *10   200 tcpsvr + 1tcpcon
       : 1tcpcon为 report tcpconn

       master  消耗的总数为 sub个数 10 + 1
       单个sub 消耗的总数为 200 + 1 = 201
       总数: 201*10 + 11 = 2021
    2. cli 内耗的socket_fd数量
       master    1tcpsvr
       sub *10   500tcpconn + 1tcpconn

       master  消耗的总数为 1 + 10
       单个sub 消耗的总数为 1万 + 1
       : cli总连接数为10万的情形

       总数: 10万 + 10 + 11 = 10万 + 21 = 100021
    3. cli连接在svr产生的socket_fd
       10 万
    4. socket_fd总数
       cli: 10万 + 21
       svr: 10万 + 2021

    测试
    初始tcp =1
    开完svr后 变为2022      -- 与svr预期一样
    开完cli后 变为202043    -- 与cli预期一样

*** 分析 内存
**** 内存受什么影响:
     直接影响
     1. 缓冲区           -- 影响cache/buff
        : read && write
     2. 进程本身数据     -- 影响used


     间接影响
     1. 协议类型         -- 影响缓冲区
     2. 业务包           -- 影响缓冲区 && 进程本身数据内存
     3. 并发数量         -- 影响缓冲区

**** 内存分析工具
     1. top    --  cpu,mem,progress总览
     2. free   --  mem总览
        : free -h 一目了然
     3. pmap pid
        #+BEGIN_EXAMPLE sh 查看进程内存情况
        # 查看进程内存, 并降序显示
        pmap <gid> | sort -n -k 2 -r
        #+END_EXAMPLE
*** 分析 cpu
**** cpu分析工具
     1. top    -- 推荐
*** 分析 网络
    : ss
*** 10万, 100万, 10m 对比测试
    #+BEGIN_EXAMPLE sh 物理机配置
    cpu:   Intel(R) Xeon(R) CPU E5-2430 0 @ 2.20GHz
           2cpu * 6核 * 2超线程
    mem:   62Gi
    带宽:  同一机器测试, 无视带宽
    #+END_EXAMPLE

    #+BEGIN_EXAMPLE sh 开始之前的状态
    # cpu.id 99.3; mem.avail 53583.8; load average 0.49 0.46 0.44
    top - 17:32:01 up 43 days,  2:16,  0 users,  load average: 0.49, 0.46, 0.44
    Tasks:   5 total,   1 running,   4 sleeping,   0 stopped,   0 zombie
    %Cpu(s):  0.5 us,  0.2 sy,  0.0 ni, 99.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
    MiB Mem :  64348.3 total,  40271.2 free,  10404.8 used,  13672.4 buff/cache
    MiB Swap:   8192.0 total,   8192.0 free,      0.0 used.  53583.8 avail Mem

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
      1 root      20   0    2384    764    696 S   0.0   0.0   0:00.02 sh
      7 root      20   0    3996   3340   2808 S   0.0   0.0   0:00.01 bash
     14 root      20   0    3996   3168   2852 S   0.0   0.0   0:00.01 bash
     21 root      20   0    3996   3320   2788 S   0.0   0.0   0:00.01 bash
     32 root      20   0    8060   3272   2776 R   0.0   0.0   0:00.01 top
    #+END_EXAMPLE

    #+BEGIN_EXAMPLE sh 只开启svr
    # 总结
    # cpu基本无变化, tcpsvr处于sleep状态;
    # 内存减少28KB,  tcpsvr还处在sleep状态
    # log日志速度非常夸张, 7分钟的时候已经8G+
    #
    # cpu.id 99.3; mem.avail 53555.4; load average 0.65,0.54,0.47
    top - 17:36:04 up 43 days,  2:20,  0 users,  load average: 0.65, 0.54, 0.47
    Tasks:  16 total,   1 running,  15 sleeping,   0 stopped,   0 zombie
    %Cpu(s):  0.3 us,  0.3 sy,  0.0 ni, 99.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
    MiB Mem :  64348.3 total,  40242.1 free,  10426.0 used,  13680.2 buff/cache
    MiB Swap:   8192.0 total,   8192.0 free,      0.0 used.  53555.1 avail Mem

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
     35 root      20   0   12928   6728   6252 S   1.3   0.0   0:01.27 svr
     40 root      20   0   12928   4172   3608 S   0.7   0.0   0:00.20 svr
     36 root      20   0   12928   4256   3692 S   0.3   0.0   0:00.22 svr
     37 root      20   0   12928   4256   3692 S   0.3   0.0   0:00.19 svr
     38 root      20   0   12928   2652   2168 S   0.3   0.0   0:00.19 svr
     41 root      20   0   12928   4028   3468 S   0.3   0.0   0:00.19 svr
     42 root      20   0   12928   2652   2168 S   0.3   0.0   0:00.20 svr
      1 root      20   0    2384    764    696 S   0.0   0.0   0:00.02 sh
      7 root      20   0    3996   3340   2808 S   0.0   0.0   0:00.01 bash
     14 root      20   0    3996   3392   2852 S   0.0   0.0   0:00.02 bash
     21 root      20   0    3996   3320   2788 S   0.0   0.0   0:00.01 bash
     39 root      20   0   12928   4176   3612 S   0.0   0.0   0:00.19 svr
     43 root      20   0   12928   3968   3412 S   0.0   0.0   0:00.19 svr
     44 root      20   0   12928   2652   2168 S   0.0   0.0   0:00.19 svr
     45 root      20   0   12928   2652   2168 S   0.0   0.0   0:00.18 svr
     47 root      20   0    8060   3264   2772 R   0.0   0.0   0:00.04 top
    #+END_EXAMPLE

    #+BEGIN_EXAMPLE sh [./cli localhost 1m 5000 60] ==> 1m只成功524288/2 - 10 - 10 = 262124
    # 总结
    # cpu减少了30.9%
    # 内存减少了6.3m
    #
    # cpu.id 68.4;  mem.avail 47107.6;  load average 6.16, 4.71, 2.45
    top - 18:11:52 up 43 days,  2:55,  0 users,  load average: 6.16, 4.71, 2.45
    Tasks:  29 total,   7 running,  22 sleeping,   0 stopped,   0 zombie
    %Cpu(s): 15.8 us, 12.5 sy,  0.0 ni, 68.4 id,  0.0 wa,  0.0 hi,  3.4 si,  0.0 st
    MiB Mem :  64348.3 total,  29513.6 free,  16936.0 used,  17898.7 buff/cache
    MiB Swap:   8192.0 total,   8192.0 free,      0.0 used.  47107.6 avail Mem

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
     52 root      20   0  185092 160752   3880 R  64.0   0.2   3:32.07 cli
     56 root      20   0  185092 160288   3844 R  60.7   0.2   3:30.05 cli
     59 root      20   0  185092 160600   3884 R  59.8   0.2   3:31.48 cli
     54 root      20   0  185092 160168   3884 S  57.9   0.2   3:30.53 cli
     55 root      20   0  185092 160576   3848 R  57.5   0.2   3:32.98 cli
     60 root      20   0  185092 160376   3884 S  56.1   0.2   3:09.15 cli
     51 root      20   0  185092 160664   3880 R  54.2   0.2   3:11.86 cli
     53 root      20   0  185092 160564   3884 R  52.8   0.2   3:31.44 cli
     58 root      20   0  185092 160180   3884 S  52.8   0.2   3:28.83 cli
     57 root      20   0  185092 160508   3884 S  52.3   0.2   3:09.76 cli
     50 root      20   0   12936   7088   6588 S   1.4   0.0   0:04.81 cli
     35 root      20   0   12928   7072   6580 S   0.9   0.0   0:24.70 svr
     36 root      20   0   35632  26956   3756 S   0.5   0.0   0:23.80 svr
     41 root      20   0   35368  26632   3608 S   0.5   0.0   0:22.88 svr
     44 root      20   0   35368  26792   3764 S   0.5   0.0   0:22.98 svr
      1 root      20   0    2384    764    696 S   0.0   0.0   0:00.02 sh
      7 root      20   0    3996   3340   2808 S   0.0   0.0   0:00.01 bash
     14 root      20   0    3996   3392   2852 S   0.0   0.0   0:00.02 bash
     21 root      20   0    3996   3332   2788 S   0.0   0.0   0:00.02 bash
     37 root      20   0   35500  26940   3756 S   0.0   0.0   0:23.05 svr
     38 root      20   0   35368  26716   3764 S   0.0   0.0   0:24.06 svr
     39 root      20   0   35368  26752   3736 S   0.0   0.0   0:24.01 svr
     40 root      20   0   35368  26748   3740 S   0.0   0.0   0:23.14 svr
     42 root      20   0   35500  26868   3764 S   0.0   0.0   0:24.12 svr
     43 root      20   0   35500  26776   3648 S   0.0   0.0   0:23.36 svr
     45 root      20   0   35632  27004   3764 S   0.0   0.0   0:22.89 svr
     47 root      20   0    8060   3264   2772 S   0.0   0.0   0:01.34 top
     61 root      20   0    3996   3324   2800 S   0.0   0.0   0:00.02 bash
    458 root      20   0    8060   3276   2780 R   0.0   0.0   0:00.07 top

    #+END_EXAMPLE
*** F&Q
    1. 问: tcp连接数量上不去
       答: 根据下面顺序进行排查
       #+BEGIN_EXAMPLE org 硬性条件
       1) 查看fd
          - 系统总fd
          - 单进程最大fd
       2) ip + port; 看tcp中的四元项的最大组合是否满足
       3) 查看mem, cpu, 带宽硬件信息
       #+END_EXAMPLE

       #+BEGIN_EXAMPLE org cli端信息
       1) connect的时候是否有错误信息, 最常见的(ip+port)不够用了
      99 Cannot assign requested address
      解决方案
      - env设置TIME_WAIT状态的快速回收
      - 代码中port复用 SO_REUSEPORT
       2) 如果connect的时候没有报错, 查看系统tcp状态 ss -a
          记得加-a, 否则查看的只是established状态的tcp. 我们需要找SYN-SENT
      SYN-SENT表示一直在等待发送
       #+END_EXAMPLE

       #+BEGIN_EXAMPLE org svr端信息
       1) 查看tcp半连接队列, 也称SYN队列
          服务端收到客户端发起的SYN请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK
      接着客户端会返回 ACK，
      服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，
      然后创建新的完全的连接，并将其添加到 accept 队列，
      等待进程调用 accept 函数时把连接取出来

      # 观察socket overflow 和 socket droped。
      # 如果应用处理全连接队列(accept queue)过慢则会导致socket overflow，影响半连接队列(syn queue)溢出而导致socket dropped

      # 查看半连接溢出情况
      netstat -s | grep -i listen
      # 645870725 times the listen queue of a socket overflowed # 全连接队列
      # 645990109 SYNs to LISTEN sockets ignored                # 半连接队列

      # 解决方案
      - 增加tcp半连接队列大小
        net.ipv4.tcp_max_syn_backlog   # syn queue上限
        # 同时需要增加全队列的大小, 半连接队列丢弃drop流程依赖全连接
      - 启动cook
        net.ipv4.tcp_syncookies=1:表示开启SYN Cookies。当出现SYN等待队列溢出的时候，启用cookies来处理少量的SYN×××。

       2) 查看tcp全连接队列, 也称accepet队列
      # -l 查看listen状态的tcpsvr
      # Recv-Q 当前SYN队列中的排队数
      # Send-Q 全队列最大值
      ss -l sport 100

      # 查看全连接溢出情况
      netstat -s | grep -i listen
      # 645870725 times the listen queue of a socket overflowed # 全连接队列
      # 645990109 SYNs to LISTEN sockets ignored                # 半连接队列

      # 解决方案:
      - 增加tcp全连接队列大小
        tcp全连接队列取决于min(somaxconn, backlog), 即ss -l 中的Send-Q
        somaxconn -- /proc/sys/net/core/somaxconn, 默认值为128
        backlog是代码tcpsvr listen(int fd, int backlog)中设置的, 这里写了20
        所以增大这2个值的最小者可以增加tcp全连接队列
      - 修改队列上限之后的 处理
        /proc/sys/net/ipv4/tcp_abort_on_overflow
        0:表示如果三次握手第三步的时候全连接队列满了那么server扔掉client发过来的ack(在server端则会认为连接没有建立起来)
        1:表示如果三次握手第三步的时候全连接队列满了，server端就会发送一个reset包给client端，表示废弃这个握手过程和这个链接。(在server端也会认为连接没有建立起来)

       3) 查看tcp状态 ss -a
          重点关注SYN-RECV
      SYN-RECV表示有大量未完成的握手请求, 可能是遭遇了SYN-RECV攻击(ddos攻击)
       #+END_EXAMPLE

** 单元测试
*** 测试 -- protobuf
    官方:
    1. 自定义了codec -- ProtoMsgCodec
       数据格式为4bytes空 + 4bytes类型名大小 + 类型名 + 序列化之后的数据
    2. 使用buffer来管理data内存

    自己的:
    1. 序列化之后放到了TCPHead的头处理, 没有处理名字

*** 测试 -- chat.cc
    官方:
    测试聊天功能

*** 测试 -- codec-cli.cc && code-svr.cc
    官方:
    1. 测试 LengthCodec

    疑问:
    1. 没有标明使用哪种codec的时候, 默认是LengthCodec?? TODONOW


*** 测试 -- daemon.cc && daemon.conf
    官方:
    1. 测试daemon功能
    2. 测试conf功能

*** 测试 -- echo.cc
    官方:
    1. ping-pong的svr实现
*** 测试 -- hsha.cc
    官方:
    1. 测试半同步半异步服务器
*** 测试 -- http-hello.cc
    官方:
    1. 测试httpServer
*** 测试 -- idle-close.cc
    官方:
    1. 测试tcpConn空闲时回调功能
*** 测试 -- reconnect.cc
    官方:
    1. 测试tcpConn重连功能
*** 测试 -- safe-close.cc
    官方:
    1. 测试多线程情形中, 关闭conn
*** 测试 -- stat.cc
    官方:
    1. 状态服务器
*** 测试 -- timer.cc
    官方:
    定时器测试
*** 测试 -- udp-cli.cc && udp-svr.cc
*** 测试 -- udp-hsha.cc
*** 测试 -- write-on-empty.cc


*** 测试 -- raw-examples/epoll.cc
    官方:
    测试epoll
*** 测试 -- raw-examples/epoll-et.cc
    官方:
    测试epoll的 ET模式
*** 测试 -- raw-examples/kqueue.cc
    测试?? TODONOW


*** 测试 -- 10m

*** 测试 -- test
    ut.cc                 --  main函数
    test_harness          --  测试管理类
    - 提供比较函数的宏接口
      比较函数会构造Tester对象, 在该析构的时候, 如果比较未通过, 则会直接调用exit(1)退出程序
    - 提供测试类宏定义, 实现测试注册和运行函数
*** 测试 -- test/conf.ut.cc
    官方:
    1. 测试conf 读取init文件 功能
*** 测试 -- test/handy.ut.cc
    官方:
    1. 测试Ip4Addr函数
    2. 测试EventBase
    3. 测试定时器
    4. 测试TcpServer 在多线程中的表现
    5. 测试TcpServer
*** 测试 -- test/tcpcli.ut.cc
    官方
    1. 测试tcp的连接状态
*** 测试 -- test/threads.ut.cc
    官方:
    1. 测试线程池
    2. 测试多线程中SafeQueue队列
*** 测试 -- test/util.ut.cc
    官方:
    1. 测试util::format
    2. 测试ExitCaller


* kernel
** 目录说明
   | 目录               | 意义                     | 备注                   |
   |--------------------+--------------------------+------------------------|
   | base               | 与底层net库的接口        | 当前底层库为qybase/net |
   |--------------------+--------------------------+------------------------|
   | kernel             | 与上层frame的接口        |                        |
   |--------------------+--------------------------+------------------------|
   | tools              | 自身或上层需要用到的函数 |                        |
   |--------------------+--------------------------+------------------------|
   | log                | 与底层log库的接口        | 当前底层库为glog       |
   |--------------------+--------------------------+------------------------|
   | define             | 头文件 && 自定义结构体   |                        |
   |--------------------+--------------------------+------------------------|
   | Makefile           |                          |                        |
   |--------------------+--------------------------+------------------------|
   | generate_depend.sh |                          |                        |
   |--------------------+--------------------------+------------------------|
   | version.sh         |                          |                        |
   |--------------------+--------------------------+------------------------|
** 文件说明
   | dir    | file           | desc                    | 备注                                 |
   |--------+----------------+-------------------------+--------------------------------------|
   | base   | base           | net初始化部分           | 事件分发器, net log日志, 信号处理    |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | create_client  | 创建socket::client      | 包含tcp, http协议                    |
   |        |                |                         | 1. x => dbsvr, centersvr             |
   |        |                |                         | 2. qy_client => gatesvr              |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | create_server  | 创建socket::server      | 包含tcp, http, stat协议              |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | net_callback   | 无用, 待删除            | 已拆分为create_client, create_server |
   |--------+----------------+-------------------------+--------------------------------------|
   |--------+----------------+-------------------------+--------------------------------------|
   | kernel | CGameCtrl      | 对外接口                |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | DataBase       | 对外DB接口              |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | IEventCallback | 对外回调接口            | socket 事件回调(连接, 关闭, 读写)    |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | IFunCallback   | ??? 忘记了.             |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | subcfg         | 子游戏加载配置文件      | 需要删除, 放到frame中处理            |
   |--------+----------------+-------------------------+--------------------------------------|
   |--------+----------------+-------------------------+--------------------------------------|
   | tool   | cmd            | 程序运行参数解析        |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | etcd           | 通过etcdctl与etcd交互   |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | redlock        | redis锁                 |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |--------+----------------+-------------------------+--------------------------------------|
   | log    | log            | glog的接口              |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |--------+----------------+-------------------------+--------------------------------------|
   | define | Packet         | IEventCallbac回调结构体 |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | define         | 自定义                  | log打印控制                          |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | heads          | 本工程使用              |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
   |        | heads_qykernel | 调用者工程使用          |                                      |
   |--------+----------------+-------------------------+--------------------------------------|
** 设计说明
   kernel作为一层接口, 封装了下层的net库, db库等实现
   对上层调用者提供通用接口, 实现业务层与底层的分离

   比如GameCtrl封装了net的功能, frame业务层只需要调用GameCtrl即可
   IEventCallback为 handy的回调事件, 封装到一个对象中, 方便管理
   DataBase封装了数据库(odbc)

** daemon
   一般情况, 应该把程序设置为守护进程来运行. 但kernel这里没必要.
   因为运行环境在docker中. docker的理念是一个docker只运行一个进程(理想状态).
   所以docker缺少对进程的管理, 即缺少了systemd

   而fork之后的父进程一般都会退出, 子游戏会进行setsid 挂载到pid=1的进程上
   一般pid=1的进程是systemd. 但docker容器不是.
   所以导致子进程退出的时候, 形成了僵尸进程Z...

   +考虑这点, kernel下的daemon并不好用+
   虽然退出后会成为僵尸进程, 但是基于下面考虑, 还是设置为守护进程:
   - 有些情形, 需要在docker容器中开启多个server进行测试, 此时设置为daemon, 比较方便
   - 某个server可能开启多个进程, 共同listen一个端口. 测试设置为daemon, 方便控制

* 待整理
** 模块意义
   | 模块名字 | 目录             | 意义             | 备注                            |
   |----------+------------------+------------------+---------------------------------|
   | net      | kernel除./kernel | 网络库           |                                 |
   |----------+------------------+------------------+---------------------------------|
   | kernel   | kernel/kernel    | 节点创建         | 1.该节点的作用(回调给frame处理) |
   |          |                  |                  | 2.与其他节点的关系(cfg控制)     |
   |----------+------------------+------------------+---------------------------------|
   | frame    | frame            | 节点具体业务处理 |                                 |
   |----------+------------------+------------------+---------------------------------|
   | etcd     | etcd服务         | 1.节点信息       |                                 |
   |          |                  | 2.节点配置文件   |                                 |
   |----------+------------------+------------------+---------------------------------|
   | redis    | redis服务        | 运行中的热点数据 |                                 |
   |----------+------------------+------------------+---------------------------------|

** server--kernel -- 耗时时间的设计
   实现: class funcost
   目标: 针对于Callback中消息号, 增加各处理端耗时打印
   具体信息:
   #+BEGIN_EXAMPLE c++ 具体打印信息
   struct time_dura{
         int64_t time_recv;       //从net读取的时间(耗时可能来源于 缓冲区一直有数据, 所以等待全部读完)
         int64_t time_in_cb;      //进入回调的时间(耗时来源于rbase的处理速度)
         int64_t time_new_over;   //内存开辟完成时间(耗时来源于内存开辟)
         int64_t time_handle;     //真正开始处理的时间(耗时来源于线程切换|等待)
         int64_t time_handle_over;//处理完成的时间(耗时来源于业务逻辑)
         int64_t time_send;       //真实的send时间(耗时来源于锁的争夺)
     };

   #+END_EXAMPLE

   分析:
   srcSvr查询
   1. query时间        -- 开始查询时间
   2. query Send时间   -- 发送时间 (耗时来源于锁的争夺)
      可以在SenMsg完成的地方调用

   center中转时间
   1. recv from net -- 从net读取的时间 (耗时可能来源于 缓冲区一直有数据, 所以等待全部读完)
      tcpconn.handleread() while之前调用
   2. 进入回调的时间  (耗时主要来源于rbase的处理速度)
      GameCtrl的onMsg回调中记录
   3. 内存开辟完成的时间(耗时来源于内存申请与copy)
   4. 真正开始处理的时间 (耗时来源于线程切换|等待)
      真实回调函数中记录
   5. 处理完成的时间 (耗时来源于业务逻辑)
      调用SendMsg之前记录
   6. 真实send的时间 (耗时来源于锁的争夺)
      SendMsg完成的地方调用

   tagSvr处理 -- 具体处理同上
   1. recv from net
   2. 进入回调的时间
   3. 真正开始处理的时间
   4. 处理完成的时间
   5. 真实send的时间

   srcSvr处理
   1. recv from net
   2. 进入回调的时间
   3. 真正开始处理的时间  -- 到此就可以知道从查询到回来的总耗时时间


* server--frame
  frame根据业务模块, 开放不同的server处理
** 模块总览
    1. [X] 登陆模块 - 重复登陆，断线重连. 登陆方式的支持， 账号密码， 游客， 微信等
    2. [X] 房间列表显示模块
       - [X] 房卡场 创建界面
       - [X] 金币场 列表展示
    3. [X] 房间创建流程
    4. [X] 子游戏模块
    5. [X] 房间结束后， 信息统计
       - [X] 大局战绩
       - [X] 小局战绩
       - [X] 录像回放
       - [X] 财富修改记录
    6. [X] 任务模块
    7. [X] 排行榜
    8. [X] 比赛场
    9. [ ] 活动模块
    10. [ ] 工会
** 服务器说明
   | 服务器名字 | 处理范围              | 有状态 | 状态量                        | 业务多线程 | 业务多线程原因   | 备注                           |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | center     | 路由                  | n      |                               | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | db         | 数据库代理            | n      |                               | y          | database操作耗时 |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | gate       | 网关                  | y      | map[gid, uid]                 | n          | 无业务逻辑       |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | logon      | 登录                  | n      |                               | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | lobby      | 大厅                  | n      |                               | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | game       | 查询, 创建, 加入 房间 | n      |                               | n          |                  | 加载了房卡场与金币场的配置文件 |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | match      | 比赛场服务器          | y      | match自身数据stage_index等    | n          |                  |                                |
   |            |                       |        | match_manager有map<int,match> |            |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | room       | 游戏房间的具体处理    | y      | 房间数据                      | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | rank       | 排行榜                | y      | rank_manager有map<int,rank>   | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | redis      | 维护redis数据         | n      |                               | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | task       | 任务                  | y      | task_manager有map<int,task>   | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | chat       | 聊天服务器            | n      |                               | n          |                  | ready to write                 |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | club       | 俱乐部服务器          | n      |                               | n          |                  | ready to write                 |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|
   | client     | 模拟client测试        | y      | ugmanager有map<gid,uid>       | n          |                  |                                |
   |------------+-----------------------+--------+-------------------------------+------------+------------------+--------------------------------|

   : 什么时候使用业务多线程
   : 当业务逻辑的处理时间耗时较久的时候, 使用业务多线程

   : 业务多线程优点 是加快了速度
   : 业务多线程缺点 编码复杂(增加了出错概率)

* server--约定俗称
*** 消息号命名规范
    为了client与server的统一, 消息号统一使用驼峰式命名, exp: SubQueryGoldRooms
    - 第一个字段 归属标志
      可能的赋值
      1) Sub  C端向S端查询
      2) Cmd  S端返回给C端
      3) L2G  logon->Game
      4) G2L  game->logon
     : 只有Lgon, game间的消息号使用 LG字样, 其他全部是Sub, Cmd
    - 第二个字段 意图  增删改查
    - 第三个字段 对象  被op对象 -- 可以没有
    - 第四个字段 消息号含义

    结构体的命名为 消息号前面增加Str
    函数的命名为 消息号前面增加On

*** 玩家的桌子号
    player.tableid
    含义:
    玩家在哪个桌子上

    用途:
    1. 登录的时候 判断断线重连
    2. 进入table时的校验, 防止加入2张桌子

    状态变化:
    1. roomSvr  table加入|坐下, 设置为桌子的tableid
    2. roomSvr  table离开,      如果是比赛场,设置为MATCH_TABLE, 否则INVALID_TABLE
    3. matchSvr 报名成功,       设置为MATCH_TABLE
    4. matchSvr 取消报名,       设置为INVALID_TABLE

*** 房间流程
    1. [X] 创建房间 -- 门票检测, 房间规则显示
       : GameServer处理
       : 房间规则使用rule_arry结构体传送给客户端显示
    2. [X] 加入房间 -- 门票检测
       : GameServer处理
       : 门票检测时 也会进行游戏资格检测
    3. [X] 房间规则在子游戏的显示
       : RoomServer frame处理
       : frame调用子游戏SubRuleDes()接口, 显示子游戏规则描述信息
    4. [X] 玩家信息在子游戏的显示
       : RoomServer frame处理
       : 玩家站起|坐下|准备|离开等动作, 会携带玩家信息, 发送给client
       : client根据动作, 判断是绘制还是删除玩家
       : 玩家财富变更后, LogonServer会通知client, 更改大厅的显示
       :                 如果在子游戏中, RoomServer frame会通知client, 更改子游戏的显示
       :                 即SubGame子游戏不再提供玩家分数相关信息给client
    5. [X] 游戏开始|一小局后 -- 门票扣除
       : RoomServer frame处理
       : 门票扣除信息 在RoomRuleCom中, 由GameServer生成
    6. [X] 每小局游戏结束 -- 游戏小局结算
       : RoomServer frame处理
       1) 小局结算写分
       2) 战绩记录
       3) 录像回放
    7. [X] 每局游戏结束后 -- 游戏资格检测
       : RoomServer frame处理
       : 数据在RoomRuleCom中, 由GameServer提供, 由CenterServer实际处理
* server--center
  center只负责路由转发, 不处理任何具体业务
** center 路由图
*** client <-> x
    #+BEGIN_SRC plantuml
title center route: client<->X
hide footbox
participant "Client" as ci << (C,#228b22) >>  order 1
participant "Gate"   as a  << (S,#ADD1B2) >>  order 2
participant "Center" as c  << (S,#ADD1B2) >>  order 3
participant "Logon"  as l  << (S,#ADD1B2) >>  order 4
participant "Lobby"  as h  << (S,#ADD1B2) >>  order 5
participant "Game"   as g  << (S,#ADD1B2) >>  order 6
participant "Room"   as r  << (S,#ADD1B2) >>  order 7


ci->a : request
a ->c : route with gid

alt  MainCMD::Logon
c ->l : route with (gid+gatesvr_id)
note left: find any logonsvr in svrmgr
note right: if login sucess, update uggr
l ->c : response (gid+gatesvr_id)
note left: find gatesvr by gatesvr_id
c ->a : route with gid
a ->ci: route

else MainCMD::Lobby
c ->h : route with uid
note left
find uid in uggr by gid,gatesvr_id
find any lobbysvr in svrmgr
end note
h ->c : response with uid
c ->a : route with gid
note right
find gid,gatesvr_id in uggr by uid
find gatesvr in svrmgr by gatesvr_id
end note
a ->ci: route

else MainCMD::Game
c ->g : route with uid
note left
find uid in uggr by gid,gatesvr_id
find any gamesvr in svrmgr
end note
g ->c : response with uid
c ->a : route with gid
note right
find gid,gatesvr_id in uggr by uid
find gatesvr in svrmgr by gatesvr_id
end note
a ->ci: route

else MainCMD::Room, MainCMD::SubRoom
c ->r : route with user
note left
find uid in uggr by gid,gatesvr_id
find roomsvr_fd in uggr by uid
find roomsvr in svrmgr by roomsvr_fd
end note
r ->c : response with user
c ->a : route with gid
note right
find gid,gatesvr_id in uggr by uid
find gatesvr in svrmgr by gatesvr_id
end note
a ->ci: route

else invalid-msg
c -> c
note left: do nothing
end
    #+END_SRC

    #+RESULTS:
    [[file:~/1.png]]

*** x <-> x
    #+BEGIN_SRC plantuml :file ~/2.png
title center route: X<->X
hide footbox
participant "X"      as x  << (S,#ADD1B2) >>  order 1
participant "Center" as c  << (S,#ADD1B2) >>  order 2
participant "Rank"   as k  << (S,#ADD1B2) >>  order 3
participant "Room"   as m  << (S,#ADD1B2) >>  order 4

alt CMDCB::RANK
  x->c: request with requestid
  note left: record map_logon<requestid, cb_f>
  c->k: route with requestid, xsvrid
  note left: find ranksvr in svrmgr
  k->c: response with requestid, xsvrid
  c->x: route with requestid
  note right: find x in svrmgr by svrid
  x->x: cb_f
  note left: delete map_logon[requestid]

else MainCB::ROOM
  x->c: request with requestid
  note left: record map_room<requestid, cb_f>
  c->m: route with requestid,xsvrid
  note left: find roomsvr in svrmgr
  m->c: response with requestid,fd
  c->x: route with requestid
  note right: find x in svrmgr by svrid
  x->x: cb_f
  note left: delete map_room[requestid]

end
    #+END_SRC

    #+RESULTS:
    [[file:~/2.png]]

** 玩家在哪个roomSvr上
   *查找方式*
   1. 根据redis.uggr中的r来确认roomserver id
   2. 先查找redis.player中的tableid,
      再查找redis.table_using中对应的serverid


   *两种方式差异*
   方式1多用于消息转发
   方式2多用于确认玩家是否在这个桌子(redis.player.tableid)上, 防止锁桌

* server--db
  db只负责转发database数据, 不处理任何具体业务
** 对外接口
   - call()
   - call_direct()

** 底层实现
   1. 对外接口底层使用callback代替msgid
      callback即自定义的RPC, 调用者可以直接在回调中处理结果数据
   2. 使用odbc驱动开发, 方便连接不同数据库
   3. 开启多个database实例, 供多线程业务层使用

** 注意事项
   1. 数据的读取顺序 必须与 db存储过程返回的顺序一致

* server--gate
  gate不负责具体业务逻辑, 转发所有数据到center

  gate作用:
  1. 过滤无效数据(socket协议数据不符的), 减少攻击对后面svr的影响
  2. client的接口, 对client隐藏后面的svr

* server--logon
  登陆服务, 更新uggr
** 重复登陆
   *判断依据*
   uggr中的gatesvrid, gid与center传递来的gatesvrid, gid进行比较,
   不一致为重复登录, 一致可能是client多次发起登录请求

   *重复处理*
   1. 通知gateSvr踢出之前的玩家c
      gateSvr校验gid,uid, 如果一致则通知client被提出, 并断开其连接
   2. 更新uggr
** 断线重连
   *判断依据*
   1. redis.player_uid中的tableid != INVALID_TALBE
   2. redis.uggr中的r != 0

   *断线处理*
   1. 如果断线, 向对应的roomSvr查询, 确认玩家是否真的在roomSvr的桌子中.
      根据结果更新uggr

* server--lobby
  大厅一些业务的处理, 当前为战绩和录像查询
* server--game
  房间配置查询 && 创建房间
  加载所有子游戏的fk和gold配置
** 对外接口
   - GetRoomRule 根据传递的规则选择, 获取房间规则
** 配置文件
   配置文件放在
   subgames/kindid/kindid.fk
   subgames/kindid/kindid.gold
** 房间规则配置
*** 房间规则分析
    *房间规则由来*
    对于每一个具体的游戏来讲, 游戏本身是规则下的流程
    这里的规则分为两大类
    一类是游戏自身的规则, 比如斗地主需要一副牌, 有三带一等各种牌型.
    这种规则本身变化不大, 影响的是游戏自身的流程.
    还有一类规则是影响游戏逻辑之外的, 比如3小局, 4小局. 比如这是房卡场的, 金币场的等等

    于是我们把所有游戏共用的规则(主要是第二类规则), 提取出来放到tagRoomRuleCom
    而对于每个子游戏不同的游戏规则, 我们只需要提供map<key, choose_index>给子游戏即可

    房间规则不区分游戏玩法.
    房卡场, 金币场, 比赛场, 俱乐部玩法的房间规则使用同一个结构体tagRoomRule
    通用房间规则 是指抽象出来供frame使用的, 使用统一结构体tagRoomRuleCom
    子游戏规则   是每个子游戏自身的规则, 在frame层以map<key, choose_index>的形式传递给子游戏, 由子游戏自己解析


    *房间规则继续分析*
    无论对于tagRoomRuleCom 还是map<key, choose_index> 都可以认为是key, value的键值对
    所以我们配置文件, 可以采取最基本的key, value形式.
    但是考虑到房卡场, 金币场等具体玩法, 我们期待的金币场也可以配置自身的游戏规则.
    比如初级场可以配置为3小局, 底分2; 中级场可以配置为2小局, 底分5;
    因此可以再进一步抽象为
    1. 先提供一个可供选择的规则配置
    2. 需要什么样的规则, 只要提供对应的choose, 就可以生成具体的tagRoomRule

*** 房间规则配置
    *目标*
    1. 金币场, 比赛场, 俱乐部模式 更好的配置游戏规则
    2. 对于房卡场, 服务器控制client的房间规则显示
       client开发的时候 不需要做任何处理


    *client使用流程*
    1. client申请创建房间
    2. server判断是否符合创建条件,  发送房间规则配置 rule_arry(在STR_Common.proto中)
       其中css控制client显示的样式
       rule表示一条规则
       #+BEGIN_EXAMPLE sh 配置举例
       css
       1
       2
       特殊规则 3, 4, 5

       rule_1  人数
       rule_2  局数
       rule_3  炸弹
       rule_4  鬼子
       rule_5  天王九
       #+END_EXAMPLE
       #+BEGIN_EXAMPLE sh client显示的样式
       人    数   "2" "3" "4"
       局    数   "2" "3" "4"
       特殊规则   炸弹o  鬼子o 天王九o
       #+END_EXAMPLE
    3. client返回 选择结果 repeated int32
       比如: 上面选择了 2人 4局, 则返回
       0
       2
       每个返回字段为byte, 返回的value index
    4. server收到后, 构造房间规则tagRoomRule


    *其他游戏模式使用流程*
    对于金币场,比赛场等使用更加简单, 直接提供choose_values即可

* server--match
** 设计理念
   matchSvr负责维护 {uid, score} 排行,
   具体的数据是roomSvr通知的matchSvr
   : match没有必要把同排行的人放到一个roomSvr, 因此不需要指定roomSvr
** 组织架构
   #+BEGIN_EXAMPLE
     kind1  --  match-type 1  -- match 1 -- {对应一系列桌子}
                              -- ....
                              -- match N
            --  ....
            --  match-type N
     ....
     kind N
   #+END_EXAMPLE

** 流程
   1. 玩家申请加入某个比赛场match_type, 如果没有空的match, 则创建一个match, 放入玩家
      设置其tableid为MATCH_TABLE, 防止进入其他桌子
      如果玩家取消比赛, tableid重置为INVALID_TABLE
      玩家掉线的时候, 如果还在比赛排队状态(tableid为MATCH_TABLE), 则按取消比赛处理
   2. 当match满足触发条件之后, 开始比赛
      matchSvr把玩家分组, 并通知roomSvr创建桌子
   3. roomSvr进行游戏, 当table大局结束的时候, 把数据(score)返回给matchSvr
   4. matchSvr进行排序, 重新分组, 继续通知roomSvr开始游戏
   5. 循环直至比赛结束为止
** 依赖关系
   依赖GameSvr, 需要GameSvr提供的GetRoomRule()接口
** 缺陷
   有状态的, 需要后期改为无状态服务器
** 配置文件
   配置文件放在subgames/kinid/kindid.match中

* server--room
** 对外接口
   - GetTable       获取table状态信息
   - GetTableUser   获取玩家是否在桌子上
   - EnterTable(uid, tableid)               进入桌子
   - EnterTable(uid, tagRoomrule)           进入桌子
   - EnterTable(vector<uid>, tagRoomrule)   进入桌子
** table设计思路
   roomSvr中的table是最基本的table, 不考虑金币场, 比赛场, 俱乐部
   只处理游戏逻辑

   也就是说, 这里Table不区分房卡场, 金币场等
   对自身影响范围:
   1. [X] 门票的问题
      门票无需特意处理, 因为在创建房间之前, 门票就已经算清楚了
   2. [X] 算分的问题
      只是把结果放出来, 至于具体如何处理, table可以不需要关心

** 战绩 && 录像回放
*** 查询
    数据存放在database中
    player_score 战绩-玩家信息
    table_record 战绩-桌子信息
    table_video  录像回放

    模拟运行:
    1. 查看大局战绩
       : player_score与table_record联查, onlyid为连接标志
       : 根据player_score.userid 与 table_record.clubid 找出top 100的onlyid
       : 根据onlyid和curcount=0 在player_score中查找所有符合条件的数据
       : 最后联查player, 联查标记为userid
    2. 查看小局战绩
       : 根据onlyid 在player_score查找即可
       : 最后联查player, 联查标志位userid
    3. 查看录像回放
       : 根据onlyid, curcount 在table_video中查找即可

*** 录像回放 写入
    1. RoomServer frmae中处理, 子游戏不需要考虑
    2. frame的SendTable()函数中, 调用录像类记录
    3. 在小局结束的时候, 调用录像类获取数据
       : 这里的数据是proto序列化为string后, 又转为了raw-string, 方便写入数据库
    4. 数据库读取出raw-string, 转为string, 再转为录像数据table_video结构体
    5. 子游戏只需要解析table_video即可

** 小局结束 数据处理
   1. [X] 玩家 门票
   2. [X] 玩家 财富变更
   3. [X] 玩家 具体输赢情况
   4. [X] 玩家 任务系统
   5. [X] 桌子 战绩
   6. [X] 桌子 回放


   财富变更表 -- 比较独立的表格 player_log_treasure
   | 玩家id | 财富类型 | 财富数量 | 备注说明 | 插入时间 |
   |--------+----------+----------+----------+----------|

   玩家输赢情况表 player_score
   | 玩家id | 当前桌子局数 | 椅子位置 | 分数 | 大赢家标志 | 唯一标志 | 插入时间 |
   |--------+--------------+----------+------+------------+----------+----------|

   战绩表 table_record
   | 桌子ID | 桌子类型(房卡, 金币) | 总局数 | 桌子玩家数 | KindID | clubid | 子游戏信息 | 唯一标志 | 插入时间 |
   |--------+----------------------+--------+------------+--------+--------+------------+----------+----------|

   战绩回放表 table_video
   | 当前桌子局数 | 回放数据 | 唯一标志 | 插入时间 |
   |--------------+----------+----------+----------|

   备注说明:
   1. 玩家财富变更均通过 玩家财富变更记录表 -- 所有财富类型
   2. 战绩表 只 记录桌子信息, 而不记录 玩家输赢信息

** 玩家动作 坐下|起立|离开|解散|换桌(金币场)
   玩家加入
   玩家坐下
   玩家起立
   玩家离开
   金币换桌
*** 旁观的处理
    : 是否旁观是由服务器根据桌子状态来判断的
    玩家加入房间的时候
    如果房间已经开始&&允许旁观, 则可以设置为旁观状态
    如果房间没有开始, 则是坐下状态

** 玩家状态
   状态1 UserStatusL
   状态2 UserStatusH
   : 两者非互斥关系, UsetStatusL内部为互斥关系, UserStatusH内部为互斥关系
   : 掉线之后未必为托管状态, 掉线8s之后, 将由掉线状态变为托管状态; 当掉线回来后, 托管状态自动取消

   #+BEGIN_EXAMPLE c++
//用户状态 low
enum UserStatusL
{
   FREE_L=0;      //没有状态
   SIT = 1;       //坐下
   STANDUP =2;    //站立(旁观)
   READY= 3;      //准备状态
   PLAYING=4;     //游戏中
};
//用户状态 high 与low不互斥
enum UserStatusH
{
   FREE_H =0;     //正常状态
   TUOGUAN =1;    //托管
   OFFLINE=2;     //掉线 -- 掉线8s之后设置为托管状态
};
   #+END_EXAMPLE

** 椅子视图
   唯一视图 真实的椅子位置
   frame: m_player_list与真实椅子视图 是通过CPlayer来转换的
   subgame: subgame实现了真实的椅子视图
   client: client存在C视图 与 真实椅子视图(S视图)的转换

** tableid生成方式
   table 由redis启动的时候预先生成100000-999999
   table_using使用zset记录tableid, 创建time. 后面删除的时候, 根据time来有选择的删除,
   比如删除5分钟之前的桌子, 提高效率.

* server--rank
** 配置文件
   *配置文件放在database rank表*
   | id   | rank_name | rank_desc | type           | sortid | award | valid    |
   | 自增 | 名字      | 描述      | 类型(唯一标志) | 优先级 | 奖励  | 是否开启 |

   读取rank
   load_rank
** 定时功能的设计
   自定义定时操作
   缺点非常明显, 如果Svr挂了, 那么可能会导致数据错乱
   所以需要额外考虑svr挂掉的情况
* server--redis
  redis 控制服务
  1. 初始化redis
  2. redis中机器人对回收等
* server--task
** 对外接口
   - PushTask(task_type, uid, score)
** 流程图
    #+BEGIN_EXAMPLE
     +--------+
     | start  |
     +--------+
         |
         |
         v
     +--------+  否
     | 触发   |------------+
     +--------+            |
       是|                 |
         |                 |
         v                 |
     +--------+  否        |
     |  完成  | -----+     |
     +--------+      |     |
         |           |     |
      是 |           |     |
         v           |     |
     +--------+      |     |
     | updata | <----+     |
     +--------+            |
         |                 |
     +---v----+            |
     | end    | <----------+
     +--------+
    #+END_EXAMPLE
    1. 触发条件判断
       - 时间start - end范围
       - 特定kind, 特定room_level下的任务.
         比如完成斗地主高级场一次
       - 用户身份的限定
         比如vip才可完成的任务
    2. 完成条件的判断
       1) 需要先根据周期重置来重置任务完成状况
       2) 任务完成状况与task配置中的任务step_all比较, 判断是否完成
    3. update
       更新任务完成状况
** 配置文件 && 中间状态
   *配置文件放到database task表*
   | 名称 | 描述 | 类型 | 优先级   | 开始时间   | 结束时间 | 重置周期     | 其他触发限制 | 总步数   | 奖励配置 |
   | name | desc | type | priority | start_time | end_time | reset_period | on_xml       | step_all | award    |

   type解释,
   斗地主初级场1次, 斗地主初级场2次, 斗地主初级场3次
   那么他们的type可以一致, 并设置priority分别为1,2,3
   这样就可以认为这三个任务是阶段性任务. 先完成斗地主初级场1次后, 才会显示斗地主初级场2次;
   完成斗地主初级场2次后,才会显示斗地主初级场3次. 形成一个阶段

   所以type相同, 认为是同一种类型任务(触发流程, 完成流程都一致), 而priority可以区分其阶段.


   *中间状态放到redis task_status_$uid_$taskid表*
   | uid | 任务id | 当前步数     | 任务完成时间 | 任务状态 |
   | uid | taskid | step_current | time         | status   |

   time应该是任务完成的时间. 昨天完成的时间, 到了今天也会重置
   status 0 未完成, 1完成未领奖, 2完成已领奖
** 任务类的设计
    1. Task
       - tagTask 任务配置的数据结构
       - 触发逻辑判断 task::bOn(...) 入参可能较多
       - 完成逻辑判断 task::bComplete(tagTaskStatus)
    2. TaskManager
       - map<taskid, Task>
       - 更新逻辑 TaskManager::updata()
       - 获取不同mtype(或sub_type)的任务
       - 增加, 删除任务

* TODO server--chat
* TODO server--club
* server--client
  模拟client, 对整个svr进行数据测试
* server--子游戏
  1. 子游戏处理范围
     游戏开始 -- 大局结束
  2. 子游戏不涉及到玩家的财富
     只会通知frame增减财富
     client子游戏玩家财富信息的显示, 实际由frame控制, 而非子游戏

** 组织架构
   FrameWork -->  TableFrameSink --> GameData

   备注: 1. tableFrameSink只是处理流程, 所有的数据都在GameData中
   2. CGameCardConfig 是GameData的辅助类.

** 牌类数据描述
   玩家 使用16位表示
   高四位 表示 玩家类型的ID  -- 比如 地主, 农民
   再四位 表示 玩家数量
   低8位  表示 玩家手牌数量


   牌使用16位表示
   高四位  表示 卡牌点数
   中四位  表示 卡牌颜色
   低8位   表示 卡牌类型组 -- groupID, 配置文件挂钩

   1方块; 2梅花; 3红桃; 4黑桃; 5表示特殊牌,  比如大王小王
   大王小王 花色为5， 值分别为 15 14

** protobuf结构
   1. 消息号
   2. 游戏状态 (抢庄, 下注, 发牌 ....) -- 断线重连相关
   3. 自定义enum, 比如牌型, 定时器等
   4. 消息号对应的结构体
   5. 断线重连对应的结构体 -- 与游戏状态一一对应
   6. 战绩中 显示的子游戏信息


* redis
** 已使用字段
   | 含义               | key                      | val                 | val_type_in_redis | 备注       |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 玩家信息           | player_$uid              | tagUserInfo         | string            | 含robot    |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 可用机器人         | robot                    | set<uid>            | unordered_set     |            |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 已用机器人         | robot_using              | set<uid>            | unordered_set     |            |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 排行榜             | rank_$rankid             | zset<uid,score>     | ordered_set       |            |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 排行榜过期时间     | rank_$rankid_expire      | int64_t             | string            | 毫秒       |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 玩家任务状态       | task_status_$uid_$taskid | tagTaskstatus       | string            |            |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | uggr索引uid        | uggr_$uid                | tagUggr             | string            | 不含机器人 |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | uggr索引gateid+gid | uggr_gg_$gatesvrid_$gid  | uid                 | string            | 不含机器人 |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 可用桌子号         | table                    | set<tableid>        | unordered_set     |            |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 已用桌子号         | table_using              | zset<tableid, time> | unordered_set     |            |
   |--------------------+--------------------------+---------------------+-------------------+------------|
   | 已用桌子号         | table_using_$tableid     | $severid_$kindid    | string            |            |
   |--------------------+--------------------------+---------------------+-------------------+------------|
** 已使用lock字段
   | 含义         | key              | 备注                 |
   |--------------+------------------+----------------------|
   | 玩家信息锁   | lock_player_$uid |                      |
   |--------------+------------------+----------------------|
* etcd
  !!! 已舍弃
** 创建容器
  docker run -d --name qy-etcd \
    --network app-tier \
    --publish 2379:2379 \
    --publish 2380:2380 \
    --env ALLOW_NONE_AUTHENTICATION=yes \
    --env ETCD_ADVERTISE_CLIENT_URLS=http://etcd-server:2379 \
    k8s.gcr.io/etcd:3.5.0-0


  docker run -d --name qy-etcd \
    --network app-tier \
    --publish 2379:2379 \
    --publish 2380:2380 \
    --env ALLOW_NONE_AUTHENTICATION=yes \
    --env ETCD_ADVERTISE_CLIENT_URLS=http://127.0.0.1:2379 \
    bitnami/etcd:latest
** http接口
   //注意range的范围为 [key, range_end)
   //put && get && get all && watch
   curl -L http://127.0.0.1:2379/v3/kv/put -X POST -d '{"key": "lili", "value": "wang"}'
   curl -L http://localhost:2379/v3/kv/range -X POST -d '{"key": "lili"}'
   curl -L http://localhost:2379/v3/kv/range -X POST -d '{"key": "svr1", "range_end": "svr2"}'
   curl -N http://localhost:2379/v3/watch -X POST -d '{"create_request": {"key":"svr/lili"} }' &

   //172.23.0.1
   curl -L http://172.23.0.1:2379/v3/kv/put -X POST -d '{"key": "L3N2ci8=", "value": "0002"}'
   curl -L http://172.23.0.1:2379/v3/kv/range -X POST -d '{"key": "c3Zy"}'
   curl -L http://localhost:2379/v3/kv/range -X POST -d '{"key": "S001", "range_end": "S003"}'
   curl -N http://localhost:2379/v3/watch -X POST -d '{"create_request": {"key":"L3N2ci8="} }'
** 使用总结
   *阶段一*
   尝试使用http (kernel内置支持)
   但因为base64问题, 舍弃

   *阶段二*
   尝试接入etcd官方指定的cpp网络库
   但因为protobuf版本, 运行不了. 通知因为编译依赖boost, 导致容器变得非常大. 舍弃

   *阶段三*
   继续使用http, 并解决base64问题(etcd中依然无法查看具体内容, 被转义了)
   因为watch舍弃. 解决不了watch的前缀问题

   *阶段四*
   代码中调用shell, shell调用etcdctl. 通过etcdctl间接操作


   *总结`*
   不要拘泥于代码, 代码,进程,容器等等, 均可使用


* 后期
  1. write && get redis中玩家数据时候 需要上锁
     - CPlayer中写入的时候都需要上锁
  2. 内存泄漏
     valgrind
  3. 无状态服务
     无状态的意义 在于方便开启一个集群
     思考一下 rank, task, match是否需要修改为无状态的
  4. callback 这里的错误处理
     struct A 序列化后的结果, 用struct B parse, 居然是正常的...
     这会导致后续 服务器非常容易崩溃, 必须解决该问题
  5. TCPCommand结构体修改
     - qybase
     - qykernel
     - frame -- 与frame是否有影响


* todonow
  1. [ ] qybase 优化
     - [ ] 优化对外接口
       : 隐藏net_tools, 简化net
       : 这块改动太大, 后期修改
  2. [ ] kernel 优化
     - [ ] 优化kernel与base, log, db等的接口设计
       : log比较麻烦, 但是很有必要, 统一log接口设计, 为后期更换glog等做准备
